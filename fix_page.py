#!/usr/bin/env python3
"""
å•ç‹¬é¡µé¢ä¿®å¤è„šæœ¬

åŠŸèƒ½ï¼šå½“å‘ç° intermediate ç›®å½•ä¸­æŸé¡µæœ‰é—®é¢˜æ—¶ï¼Œ
å¯ä»¥å•ç‹¬é‡æ–°å¤„ç†è¯¥é¡µé¢å¹¶æ›¿æ¢åŸæ–‡ä»¶ï¼Œç„¶åé‡æ–°åˆå¹¶å®Œæ•´çš„ output.md

ä½¿ç”¨æ–¹æ³•:
    # ä¿®å¤ç¬¬5é¡µ
    python fix_page.py output 5
    
    # ä¿®å¤å¤šé¡µ
    python fix_page.py output 3,5,7
    
    # åªç”Ÿæˆå•é¡µæ–‡ä»¶ï¼Œä¸é‡æ–°åˆå¹¶ output.md
    python fix_page.py output 5 --no-merge
"""

import os
import sys
import json
import re
import argparse
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import time
from datetime import datetime
import base64

from pdf2image import convert_from_path
from PIL import Image
import requests

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass


class APIClient:
    """APIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, api_base: str, model: str, max_retries: int = 3, timeout: int = 120):
        self.api_key = api_key
        self.api_base = api_base.rstrip("/")
        self.model = model
        self.max_retries = max_retries
        self.timeout = timeout
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    
    def call_with_image(self, image_path: str, prompt: str, max_tokens: int = 10000) -> str:
        """è°ƒç”¨å¤šæ¨¡æ€APIï¼ˆå¸¦å›¾ç‰‡ï¼‰"""
        base64_image = self.encode_image_to_base64(image_path)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.2
        }
        
        return self._make_request(payload)
    
    def _make_request(self, payload: dict) -> str:
        """å‘é€è¯·æ±‚"""
        last_error = None
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    f"{self.api_base}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=self.timeout
                )
                response.raise_for_status()
                return response.json()["choices"][0]["message"]["content"]
            except Exception as e:
                last_error = e
                print(f"  âš ï¸ APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)
        
        raise last_error if last_error else RuntimeError("APIè°ƒç”¨å¤±è´¥")


class PageFixer:
    """é¡µé¢ä¿®å¤å™¨"""
    
    def __init__(
        self,
        output_dir: str,
        api_key: str,
        api_base: str,
        model: str,
        max_retries: int = 3,
        timeout: int = 120
    ):
        self.output_dir = Path(output_dir)
        self.api_client = APIClient(api_key, api_base, model, max_retries, timeout)
        
        # éªŒè¯ç›®å½•ç»“æ„
        self.pages_dir = self.output_dir / "pages"
        self.figures_dir = self.output_dir / "figures"
        self.tables_dir = self.output_dir / "tables"
        self.intermediate_dir = self.output_dir / "intermediate"
        self.raw_extracted_dir = self.intermediate_dir / "01_raw_extracted"
        self.with_images_dir = self.intermediate_dir / "02_with_images"
        
        if not self.pages_dir.exists():
            raise FileNotFoundError(f"pages ç›®å½•ä¸å­˜åœ¨: {self.pages_dir}")
    
    def get_total_pages(self) -> int:
        """è·å–æ€»é¡µæ•°"""
        page_files = list(self.pages_dir.glob("page_*.png"))
        return len(page_files)
    
    def extract_figures_and_tables(
        self, 
        image_path: str, 
        page_num: int
    ) -> Tuple[List[Dict], List[Dict]]:
        """ä»é¡µé¢ä¸­æå–æ’å›¾å’Œè¡¨æ ¼ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰"""
        print(f"  ğŸ” æ­£åœ¨é‡æ–°è¯†åˆ«ç¬¬ {page_num} é¡µçš„æ’å›¾å’Œè¡¨æ ¼...")
        
        prompt = """è¯·åˆ†æè¿™å¼ å­¦æœ¯è®ºæ–‡é¡µé¢ï¼Œè¯†åˆ«æ‰€æœ‰çš„æ’å›¾ï¼ˆfiguresï¼‰å’Œè¡¨æ ¼ï¼ˆtablesï¼‰ã€‚

è¯†åˆ«è¦æ±‚ï¼š
1. è¯†åˆ« Figure/Fig. å’Œ Tableï¼Œè·å–ç¼–å·å’Œæ ‡é¢˜
2. è¾¹ç•Œæ¡†åæ ‡ [x_min, y_min, x_max, y_max]ï¼ˆç›¸å¯¹äºå›¾ç‰‡çš„ç™¾åˆ†æ¯”ï¼‰
3. ç´§å¯†åŒ…å›´æ•´ä¸ªæ’å›¾/è¡¨æ ¼åŠå…¶æ ‡é¢˜

è¾“å‡ºJSONæ ¼å¼ï¼š
{
    "figures": [
        {"id": "Figure 1", "title": "...", "bbox": [0.1, 0.2, 0.9, 0.6]}
    ],
    "tables": [
        {"id": "Table 1", "title": "...", "bbox": [0.1, 0.7, 0.9, 0.95]}
    ]
}

æ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºæ•°ç»„ã€‚åªè¿”å›JSONã€‚"""
        
        try:
            response = self.api_client.call_with_image(image_path, prompt, max_tokens=10000)
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
            else:
                data = {"figures": [], "tables": []}
        except Exception as e:
            print(f"    âš ï¸ è¯†åˆ«å¤±è´¥: {e}")
            data = {"figures": [], "tables": []}
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.figures_dir.mkdir(exist_ok=True)
        self.tables_dir.mkdir(exist_ok=True)
        
        figures = []
        tables = []
        
        # å¤„ç†æ’å›¾
        img = Image.open(image_path)
        width, height = img.size
        
        for fig in data.get("figures", []):
            try:
                bbox = fig.get("bbox", [0, 0, 1, 1])
                left = max(0, int(bbox[0] * width))
                top = max(0, int(bbox[1] * height))
                right = min(width, int(bbox[2] * width))
                bottom = min(height, int(bbox[3] * height))
                
                if right - left < 50 or bottom - top < 50:
                    continue
                
                cropped = img.crop((left, top, right, bottom))
                fig_id = fig.get("id", f"Figure_{page_num}")
                
                # ç¡®ä¿æ–‡ä»¶ååŒ…å«page_num
                safe_id = re.sub(r'[^\w]', '_', fig_id.lower())
                fig_filename = f"page{page_num:03d}_{safe_id}.png"
                
                fig_relative_path = f"figures/{fig_filename}"
                fig_absolute_path = self.figures_dir / fig_filename
                cropped.save(fig_absolute_path, "PNG")
                
                figures.append({
                    "id": fig_id,
                    "title": fig.get("title", ""),
                    "path": fig_relative_path,
                    "absolute_path": str(fig_absolute_path),
                    "filename": fig_filename,
                    "page": page_num
                })
                print(f"    âœ“ å·²æå–/è¦†ç›–æ’å›¾: {fig_id} â†’ {fig_filename}")
            except Exception as e:
                print(f"    âš ï¸ æå–æ’å›¾å¤±è´¥: {e}")
        
        # å¤„ç†è¡¨æ ¼
        for tab in data.get("tables", []):
            try:
                bbox = tab.get("bbox", [0, 0, 1, 1])
                left = max(0, int(bbox[0] * width))
                top = max(0, int(bbox[1] * height))
                right = min(width, int(bbox[2] * width))
                bottom = min(height, int(bbox[3] * height))
                
                if right - left < 50 or bottom - top < 50:
                    continue
                
                cropped = img.crop((left, top, right, bottom))
                tab_id = tab.get("id", f"Table_{page_num}")
                
                safe_id = re.sub(r'[^\w]', '_', tab_id.lower())
                tab_filename = f"page{page_num:03d}_{safe_id}.png"
                
                tab_relative_path = f"tables/{tab_filename}"
                tab_absolute_path = self.tables_dir / tab_filename
                cropped.save(tab_absolute_path, "PNG")
                
                tables.append({
                    "id": tab_id,
                    "title": tab.get("title", ""),
                    "path": tab_relative_path,
                    "absolute_path": str(tab_absolute_path),
                    "filename": tab_filename,
                    "page": page_num
                })
                print(f"    âœ“ å·²æå–/è¦†ç›–è¡¨æ ¼: {tab_id} â†’ {tab_filename}")
            except Exception as e:
                print(f"    âš ï¸ æå–è¡¨æ ¼å¤±è´¥: {e}")
        
        return figures, tables
    
    def extract_text_from_page(
        self,
        image_path: str,
        page_num: int,
        total_pages: int
    ) -> str:
        """ä»é¡µé¢å›¾ç‰‡ä¸­æå–è‹±æ–‡æ–‡æœ¬"""
        print(f"  ğŸ“ æ­£åœ¨é‡æ–°æå–ç¬¬ {page_num} é¡µçš„è‹±æ–‡æ–‡æœ¬...")
        
        prompt = f"""è¯·ä»”ç»†åˆ†æè¿™å¼ å­¦æœ¯è®ºæ–‡é¡µé¢çš„å›¾ç‰‡ï¼Œæå–é¡µé¢ä¸Šçš„æ‰€æœ‰è‹±æ–‡æ–‡æœ¬å†…å®¹ã€‚

**é‡è¦ï¼šæå–èŒƒå›´è¦æ±‚**
1. **åªæå–æ­£æ–‡æ–‡å­—**ï¼Œä¸åŒ…æ‹¬ï¼š
   - âŒ å›¾ç‰‡ï¼ˆFigureï¼‰ä¸­çš„æ–‡å­—
   - âŒ è¡¨æ ¼ï¼ˆTableï¼‰ä¸­çš„æ–‡å­—
   - âŒ å›¾ç‰‡å’Œè¡¨æ ¼çš„æ ‡é¢˜ï¼ˆFigure X:, Table X:ï¼‰

2. **åªæå–ä»¥ä¸‹æ–‡å­—å†…å®¹**ï¼š
   - âœ“ æ ‡é¢˜ï¼ˆTitle, Section headersç­‰ï¼‰
   - âœ“ æ­£æ–‡æ®µè½
   - âœ“ æ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•ã€ç»“æœã€ç»“è®º
   - âœ“ å‚è€ƒæ–‡çŒ®å¼•ç”¨æ ‡è®°
   - âœ“ é¡µçœ‰é¡µè„šä¿¡æ¯

3. **é˜…è¯»é¡ºåºè¦æ±‚**ï¼š
   - åŒæ å¸ƒå±€ï¼šå…ˆå·¦æ åå³æ 
   - å•æ å¸ƒå±€ï¼šä»ä¸Šåˆ°ä¸‹

4. **æ ¼å¼è¦æ±‚**ï¼š
   - ä½¿ç”¨Markdownæ ¼å¼
   - æ ‡é¢˜ç”¨ # ## ### æ ‡è®°
   - æ®µè½ä¹‹é—´ä¿ç•™ç©ºè¡Œ
   - æ•°å­¦å…¬å¼ä¿ç•™ LaTeX æ ¼å¼

5. **æ ‡æ³¨æ’å›¾å’Œè¡¨æ ¼ä½ç½®**ï¼š
   - åœ¨æ’å›¾å‡ºç°çš„ä½ç½®æ ‡è®°ï¼š[FIGURE: Figure 1]
   - åœ¨è¡¨æ ¼å‡ºç°çš„ä½ç½®æ ‡è®°ï¼š[TABLE: Table 1]

è¯·ç›´æ¥è¿”å›æå–çš„æ–‡æœ¬ã€‚"""
        
        raw_text = self.api_client.call_with_image(image_path, prompt, max_tokens=10000)
        
        # ä¿å­˜åˆ°ä¸­é—´ç»“æœ
        self.raw_extracted_dir.mkdir(parents=True, exist_ok=True)
        raw_file = self.raw_extracted_dir / f"page_{page_num:03d}.md"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write(raw_text)
        print(f"    âœ“ å·²ä¿å­˜åŸå§‹æå–: {raw_file}")
        
        return raw_text
    
    def insert_image_references(
        self,
        markdown: str,
        figures: List[Dict],
        tables: List[Dict],
        page_num: int
    ) -> str:
        """ä¸ºå•é¡µæ’å…¥å›¾ç‰‡å¼•ç”¨"""
        print(f"  ğŸ–¼ï¸  æ­£åœ¨ä¸ºç¬¬ {page_num} é¡µæ’å…¥å›¾ç‰‡å¼•ç”¨...")
        
        inserted_count = 0
        
        # æ›¿æ¢ [FIGURE: X] æ ‡è®°
        for fig in figures:
            fig_id = fig["id"]
            patterns = [
                rf'\[FIGURE:\s*{re.escape(fig_id)}\]',
                rf'\[FIGURE:\s*{re.escape(fig_id.replace(" ", ""))}\]',
                rf'\[FIGURE:\s*{re.escape(fig_id.replace("Figure ", "Fig. "))}\]',
            ]
            
            for pattern in patterns:
                if re.search(pattern, markdown, re.IGNORECASE):
                    img_ref = f'\n\n![{fig_id}: {fig.get("title", "")}]({fig["path"]})\n\n'
                    markdown = re.sub(pattern, img_ref, markdown, flags=re.IGNORECASE, count=1)
                    inserted_count += 1
                    print(f"    âœ“ å·²æ’å…¥ {fig_id}")
                    break
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°æ ‡è®°ï¼Œåœ¨æ–‡æœ¬ä¸­æ’å…¥
                text_patterns = [
                    rf'{re.escape(fig_id)}[\s\.,;:]',
                    rf'{re.escape(fig_id.replace(" ", ""))}[\s\.,;:]',
                ]
                for text_pattern in text_patterns:
                    match = re.search(text_pattern, markdown, re.IGNORECASE)
                    if match:
                        insert_pos = match.start()
                        img_ref = f'\n\n![{fig_id}: {fig.get("title", "")}]({fig["path"]})\n\n'
                        markdown = markdown[:insert_pos] + img_ref + markdown[insert_pos:]
                        inserted_count += 1
                        print(f"    âœ“ å·²åœ¨æ–‡æœ¬ä½ç½®æ’å…¥ {fig_id}")
                        break
        
        # æ›¿æ¢ [TABLE: X] æ ‡è®°
        for tab in tables:
            tab_id = tab["id"]
            patterns = [
                rf'\[TABLE:\s*{re.escape(tab_id)}\]',
                rf'\[TABLE:\s*{re.escape(tab_id.replace(" ", ""))}\]',
            ]
            
            for pattern in patterns:
                if re.search(pattern, markdown, re.IGNORECASE):
                    img_ref = f'\n\n![{tab_id}: {tab.get("title", "")}]({tab["path"]})\n\n'
                    markdown = re.sub(pattern, img_ref, markdown, flags=re.IGNORECASE, count=1)
                    inserted_count += 1
                    print(f"    âœ“ å·²æ’å…¥ {tab_id}")
                    break
            else:
                text_patterns = [
                    rf'{re.escape(tab_id)}[\s\.,;:]',
                    rf'{re.escape(tab_id.replace(" ", ""))}[\s\.,;:]',
                ]
                for text_pattern in text_patterns:
                    match = re.search(text_pattern, markdown, re.IGNORECASE)
                    if match:
                        insert_pos = match.start()
                        img_ref = f'\n\n![{tab_id}: {tab.get("title", "")}]({tab["path"]})\n\n'
                        markdown = markdown[:insert_pos] + img_ref + markdown[insert_pos:]
                        inserted_count += 1
                        print(f"    âœ“ å·²åœ¨æ–‡æœ¬ä½ç½®æ’å…¥ {tab_id}")
                        break
        
        print(f"    æ€»è®¡æ’å…¥ {inserted_count} ä¸ªå›¾ç‰‡/è¡¨æ ¼")
        
        return markdown
    
    def fix_single_page(self, page_num: int) -> str:
        """ä¿®å¤å•é¡µ"""
        print(f"\n{'='*70}")
        print(f"ğŸ”§ æ­£åœ¨ä¿®å¤ç¬¬ {page_num} é¡µ")
        print(f"{'='*70}")
        
        # æ£€æŸ¥åŸå§‹å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        image_path = self.pages_dir / f"page_{page_num:03d}.png"
        if not image_path.exists():
            raise FileNotFoundError(f"ç¬¬ {page_num} é¡µå›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        
        total_pages = self.get_total_pages()
        
        # æ­¥éª¤1ï¼šæå–æ’å›¾å’Œè¡¨æ ¼ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        figures, tables = self.extract_figures_and_tables(str(image_path), page_num)
        
        # æ­¥éª¤2ï¼šæå–è‹±æ–‡æ–‡æœ¬
        raw_text = self.extract_text_from_page(str(image_path), page_num, total_pages)
        
        # æ­¥éª¤3ï¼šæ’å…¥å›¾ç‰‡å¼•ç”¨
        processed_markdown = self.insert_image_references(raw_text, figures, tables, page_num)
        
        # æ­¥éª¤4ï¼šä¿å­˜åˆ°ä¸­é—´ç»“æœï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        self.with_images_dir.mkdir(parents=True, exist_ok=True)
        output_file = self.with_images_dir / f"page_{page_num:03d}.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(processed_markdown)
        
        print(f"\nâœ… ç¬¬ {page_num} é¡µä¿®å¤å®Œæˆï¼")
        print(f"   åŸå§‹å›¾ç‰‡: {image_path}")
        print(f"   æå–æ–‡ä»¶: {self.raw_extracted_dir / f'page_{page_num:03d}.md'}")
        print(f"   æœ€ç»ˆæ–‡ä»¶: {output_file}")
        print(f"   å›¾ç‰‡æ•°: {len(figures)}, è¡¨æ ¼æ•°: {len(tables)}")
        
        return str(output_file)
    
    def merge_all_pages(self):
        """é‡æ–°åˆå¹¶æ‰€æœ‰é¡µé¢ç”Ÿæˆ output.md"""
        print(f"\n{'='*70}")
        print("ğŸ“ æ­£åœ¨é‡æ–°åˆå¹¶æ‰€æœ‰é¡µé¢...")
        print(f"{'='*70}")
        
        total_pages = self.get_total_pages()
        print(f"  æ€»é¡µæ•°: {total_pages}")
        
        # æ”¶é›†æ‰€æœ‰é¡µé¢
        all_pages = []
        missing_pages = []
        
        for i in range(1, total_pages + 1):
            page_file = self.with_images_dir / f"page_{i:03d}.md"
            if page_file.exists():
                with open(page_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                all_pages.append(content)
                print(f"  âœ“ å·²åŠ è½½ç¬¬ {i} é¡µ")
            else:
                missing_pages.append(i)
                print(f"  âš ï¸  ç¬¬ {i} é¡µæ–‡ä»¶ä¸å­˜åœ¨: {page_file}")
        
        if missing_pages:
            print(f"\nâš ï¸  è­¦å‘Š: ä»¥ä¸‹é¡µé¢æ–‡ä»¶ç¼ºå¤±: {missing_pages}")
            print(f"   è¿™äº›é¡µé¢å°†ä¸ä¼šè¢«åŒ…å«åœ¨æœ€ç»ˆçš„ output.md ä¸­")
            response = input("   æ˜¯å¦ç»§ç»­? (y/n): ")
            if response.lower() != 'y':
                print("   æ“ä½œå·²å–æ¶ˆ")
                return None
        
        # åˆå¹¶
        full_markdown = "\n\n---\n\n".join(all_pages)
        
        # åå¤„ç†
        full_markdown = re.sub(r'\n{3,}', '\n\n', full_markdown)
        full_markdown = re.sub(r'!\[([^\]]*)\]\s*\(\s*([^)]+)\s*\)', r'![\1](\2)', full_markdown)
        full_markdown = full_markdown.strip()
        
        # ä¿å­˜
        output_file = self.output_dir / "output.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(full_markdown)
        
        print(f"\nâœ… åˆå¹¶å®Œæˆï¼")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"   åŒ…å«é¡µé¢: {len(all_pages)}/{total_pages}")
        print(f"   æ€»å­—ç¬¦æ•°: {len(full_markdown)}")
        
        return str(output_file)
    
    def update_summary(self, page_num: int, figures: List[Dict], tables: List[Dict]):
        """æ›´æ–° summary.json"""
        summary_file = self.output_dir / "summary.json"
        
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary = json.load(f)
        else:
            summary = {
                "total_pages": self.get_total_pages(),
                "figures_count": 0,
                "tables_count": 0,
                "figures": [],
                "tables": []
            }
        
        # ç§»é™¤æ—§çš„è¯¥é¡µæ•°æ®
        summary["figures"] = [f for f in summary.get("figures", []) if f.get("page") != page_num]
        summary["tables"] = [t for t in summary.get("tables", []) if t.get("page") != page_num]
        
        # æ·»åŠ æ–°æ•°æ®
        for fig in figures:
            summary["figures"].append({
                "id": fig["id"],
                "path": fig["path"],
                "title": fig.get("title", ""),
                "page": fig["page"],
                "filename": fig["filename"]
            })
        
        for tab in tables:
            summary["tables"].append({
                "id": tab["id"],
                "path": tab["path"],
                "title": tab.get("title", ""),
                "page": tab["page"],
                "filename": tab["filename"]
            })
        
        # æ›´æ–°è®¡æ•°
        summary["figures_count"] = len(summary["figures"])
        summary["tables_count"] = len(summary["tables"])
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"  âœ“ å·²æ›´æ–° {summary_file}")


def parse_page_numbers(page_str: str) -> List[int]:
    """è§£æé¡µç å­—ç¬¦ä¸²"""
    pages = []
    
    # æ”¯æŒæ ¼å¼: "5" æˆ– "3,5,7" æˆ– "1-5" æˆ– "1-5,7,9-11"
    parts = page_str.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            # èŒƒå›´æ ¼å¼: 1-5
            start, end = part.split('-')
            pages.extend(range(int(start), int(end) + 1))
        else:
            # å•é¡µæ ¼å¼: 5
            pages.append(int(part))
    
    return sorted(list(set(pages)))  # å»é‡å¹¶æ’åº


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä¿®å¤PDFå¤„ç†ä¸­çš„å•ä¸ªæˆ–å¤šä¸ªé¡µé¢"
    )
    parser.add_argument("output_dir", help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆåŒ…å«pages/ã€intermediate/ç­‰ï¼‰")
    parser.add_argument("pages", help="è¦ä¿®å¤çš„é¡µç ï¼Œæ”¯æŒæ ¼å¼: 5 | 3,5,7 | 1-5 | 1-5,7,9-11")
    parser.add_argument("--no-merge", action="store_true", help="ä¸é‡æ–°åˆå¹¶ output.md")
    parser.add_argument("--api-key", default=os.getenv("API_KEY", ""), help="APIå¯†é’¥")
    parser.add_argument("--api-base", default=os.getenv("API_BASE", "https://api.openai.com/v1"), help="APIåŸºç¡€URL")
    parser.add_argument("--model", default=os.getenv("MODEL", "gpt-4o"), help="æ¨¡å‹åç§°")
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å‡ºç›®å½•
    if not os.path.exists(args.output_dir):
        print(f"âŒ é”™è¯¯: è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {args.output_dir}")
        sys.exit(1)
    
    # éªŒè¯APIé…ç½®
    if not args.api_key:
        print("âŒ é”™è¯¯: æœªé…ç½®APIå¯†é’¥ï¼ˆAPI_KEYï¼‰")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY æˆ–ä½¿ç”¨ --api-key å‚æ•°")
        sys.exit(1)
    
    # è§£æé¡µç 
    try:
        page_numbers = parse_page_numbers(args.pages)
        print(f"ğŸ“„ å°†ä¿®å¤ä»¥ä¸‹é¡µé¢: {page_numbers}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•è§£æé¡µç  '{args.pages}': {e}")
        sys.exit(1)
    
    # åˆ›å»ºä¿®å¤å™¨
    try:
        fixer = PageFixer(
            output_dir=args.output_dir,
            api_key=args.api_key,
            api_base=args.api_base,
            model=args.model
        )
    except Exception as e:
        print(f"âŒ é”™è¯¯: åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # ä¿®å¤æ¯ä¸€é¡µ
    all_figures = []
    all_tables = []
    
    try:
        for page_num in page_numbers:
            try:
                fixer.fix_single_page(page_num)
                # è¿™é‡Œéœ€è¦é‡æ–°è·å–figureså’Œtablesæ¥æ›´æ–°summary
                # ç®€åŒ–å¤„ç†ï¼šç”¨æˆ·å¯ä»¥é€šè¿‡å®Œæ•´é‡è·‘æ¥æ›´æ–°summary
            except Exception as e:
                print(f"\nâŒ ä¿®å¤ç¬¬ {page_num} é¡µæ—¶å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # é‡æ–°åˆå¹¶
        if not args.no_merge:
            fixer.merge_all_pages()
        else:
            print(f"\nâš ï¸  è·³è¿‡äº†é‡æ–°åˆå¹¶ output.mdï¼ˆä½¿ç”¨ --no-merge å‚æ•°ï¼‰")
            print(f"   ä¿®å¤çš„é¡µé¢æ–‡ä»¶å·²ä¿å­˜åˆ° intermediate/02_with_images/")
        
        print(f"\nğŸ‰ ä¿®å¤å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
