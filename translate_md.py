#!/usr/bin/env python3
"""
Markdownç¿»è¯‘è„šæœ¬

åŠŸèƒ½ï¼šå°†è‹±æ–‡Markdownæ–‡ä»¶ç¿»è¯‘æˆä¸­æ–‡
- ç¿»è¯‘æ‰€æœ‰è‹±æ–‡æ–‡å­—å†…å®¹
- å…¬å¼ä¿æŒä¸å˜
- è¡¨æ ¼ã€å›¾ç‰‡ã€ä»£ç æ¡†ã€ç®—æ³•æ¡†åªç¿»è¯‘å¿…è¦çš„æ³¨é‡Š
- äººåä¸å¿…ç¿»è¯‘
- ä¿æŒMarkdownæ ¼å¼å’Œç»“æ„

ä½¿ç”¨æ–¹æ³•:
    python translate_md.py output/output.md
    
è¾“å‡ºï¼š
    åœ¨åŒçº§ç›®å½•ç”Ÿæˆ output_zh.md
"""

import os
import sys
import re
import argparse
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import time
import requests

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass


class ProtectedBlock:
    """å—ä¿æŠ¤çš„å†…å®¹å—"""
    def __init__(self, placeholder: str, original: str, block_type: str):
        self.placeholder = placeholder
        self.original = original
        self.block_type = block_type


class MarkdownTranslator:
    """Markdownç¿»è¯‘å™¨"""
    
    def __init__(self, api_key: str, api_base: str, model: str, max_retries: int = 3, timeout: int = 120):
        self.api_key = api_key
        self.api_base = api_base.rstrip("/")
        self.model = model
        self.max_retries = max_retries
        self.timeout = timeout
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.translation_cache = {}
    
    def call_api(self, prompt: str, max_tokens: int = 10000, temperature: float = 0.3) -> str:
        """è°ƒç”¨API"""
        payload = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        last_error = None
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    f"{self.api_base}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=self.timeout
                )
                response.raise_for_status()
                return response.json()["choices"][0]["message"]["content"]
            except Exception as e:
                last_error = e
                print(f"  âš ï¸ APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)
        
        raise last_error if last_error else RuntimeError("APIè°ƒç”¨å¤±è´¥")
    
    def protect_inline_math_formulas(self, text: str, protected_blocks: List[ProtectedBlock]) -> str:
        """ä¸“é—¨å¤„ç†è¡Œå†…æ•°å­¦å…¬å¼ $...$ï¼Œå¤„ç†åµŒå¥—å¤§æ‹¬å·çš„æƒ…å†µ"""
        protected_index = len([b for b in protected_blocks if b.block_type == "inline_math"])
        
        # ä½¿ç”¨çŠ¶æ€æœºæ¥å¤„ç†åµŒå¥—çš„å¤§æ‹¬å·
        result = []
        i = 0
        n = len(text)
        
        while i < n:
            if text[i] == '$':
                # æ£€æŸ¥æ˜¯å¦æ˜¯ $$
                if i + 1 < n and text[i + 1] == '$':
                    # è¿™æ˜¯ $$...$$ å—ï¼Œè·³è¿‡ï¼Œç”±å…¶ä»–å‡½æ•°å¤„ç†
                    result.append(text[i])
                    i += 1
                    continue
                
                # æ‰¾åˆ°åŒ¹é…çš„ $
                start = i
                i += 1
                brace_depth = 0
                
                while i < n:
                    if text[i] == '\\' and i + 1 < n:
                        # è½¬ä¹‰å­—ç¬¦ï¼Œè·³è¿‡ä¸‹ä¸€ä¸ªå­—ç¬¦
                        i += 2
                        continue
                    elif text[i] == '{':
                        brace_depth += 1
                    elif text[i] == '}':
                        brace_depth -= 1
                    elif text[i] == '$' and brace_depth == 0:
                        # æ‰¾åˆ°åŒ¹é…çš„ $
                        i += 1
                        formula = text[start:i]
                        placeholder = f"<<<INLINE_MATH_{protected_index:04d}>>>"
                        protected_blocks.append(ProtectedBlock(placeholder, formula, "inline_math"))
                        result.append(placeholder)
                        protected_index += 1
                        break
                    
                    i += 1
                else:
                    # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ $ï¼Œä¿ç•™åŸæ ·
                    result.append(text[start:i])
            else:
                result.append(text[i])
                i += 1
        
        return ''.join(result)
    
    def protect_blocks(self, text: str) -> Tuple[str, List[ProtectedBlock]]:
        """
        ä¿æŠ¤ä¸éœ€è¦ç¿»è¯‘çš„å—
        è¿”å›ï¼š(å¤„ç†åçš„æ–‡æœ¬, ä¿æŠ¤å—åˆ—è¡¨)
        """
        protected_blocks = []
        protected_index = 0
        
        # 1. ä¿æŠ¤ä»£ç å— ```...```
        def protect_code_block(match):
            nonlocal protected_index
            placeholder = f"<<<CODE_BLOCK_{protected_index:04d}>>>"
            protected_blocks.append(ProtectedBlock(placeholder, match.group(0), "code_block"))
            protected_index += 1
            return placeholder
        
        text = re.sub(r'```[\s\S]*?```', protect_code_block, text)
        
        # 2. ä¿æŠ¤è¡Œå†…ä»£ç  `...`
        def protect_inline_code(match):
            nonlocal protected_index
            placeholder = f"<<<INLINE_CODE_{protected_index:04d}>>>"
            protected_blocks.append(ProtectedBlock(placeholder, match.group(0), "inline_code"))
            protected_index += 1
            return placeholder
        
        text = re.sub(r'`[^`]+`', protect_inline_code, text)
        
        # 3. ä¿æŠ¤æ•°å­¦å…¬å¼ $$...$$
        def protect_math_block(match):
            nonlocal protected_index
            placeholder = f"<<<MATH_BLOCK_{protected_index:04d}>>>"
            protected_blocks.append(ProtectedBlock(placeholder, match.group(0), "math_block"))
            protected_index += 1
            return placeholder
        
        text = re.sub(r'\$\$[\s\S]*?\$\$', protect_math_block, text)
        
        # 4. ä¿æŠ¤è¡Œå†…æ•°å­¦å…¬å¼ $...$ï¼ˆä½¿ç”¨ä¸“é—¨çš„å‡½æ•°å¤„ç†åµŒå¥—å¤§æ‹¬å·ï¼‰
        text = self.protect_inline_math_formulas(text, protected_blocks)
        
        # 5. ä¿æŠ¤å›¾ç‰‡å¼•ç”¨ ![...](...)
        def protect_image(match):
            nonlocal protected_index
            placeholder = f"<<<IMAGE_{protected_index:04d}>>>"
            protected_blocks.append(ProtectedBlock(placeholder, match.group(0), "image"))
            protected_index += 1
            return placeholder
        
        text = re.sub(r'!\[[^\]]*\]\([^)]+\)', protect_image, text)
        
        # 6. ä¿æŠ¤HTMLæ ‡ç­¾
        def protect_html(match):
            nonlocal protected_index
            placeholder = f"<<<HTML_{protected_index:04d}>>>"
            protected_blocks.append(ProtectedBlock(placeholder, match.group(0), "html"))
            protected_index += 1
            return placeholder
        
        text = re.sub(r'<[^>]+>', protect_html, text)
        
        return text, protected_blocks
    
    def restore_blocks(self, text: str, protected_blocks: List[ProtectedBlock]) -> str:
        """æ¢å¤ä¿æŠ¤çš„å†…å®¹å—"""
        # æŒ‰ç´¢å¼•ä»å¤§åˆ°å°æ’åºï¼Œé¿å…æ›¿æ¢æ—¶å½±å“å…¶ä»–å ä½ç¬¦
        sorted_blocks = sorted(protected_blocks, key=lambda x: x.placeholder, reverse=True)
        
        for block in sorted_blocks:
            if block.placeholder in text:
                text = text.replace(block.placeholder, block.original)
        
        return text
    
    def fix_broken_placeholders(self, text: str, all_blocks: List[ProtectedBlock]) -> str:
        """ä¿®å¤æ®‹ç¼ºçš„å ä½ç¬¦ï¼ˆå¦‚ <<<INLINE_MATH_0053>ï¼‰"""
        # æŸ¥æ‰¾æ‰€æœ‰ç±»ä¼¼å ä½ç¬¦ä½†ä¸å®Œæ•´çš„æ¨¡å¼
        # åŒ¹é… <<<TYPE_INDEX> æˆ– <<<TYPE_INDEX>> ç­‰ä¸å®Œæ•´å½¢å¼
        broken_pattern = r'<<<([A-Z_]+)_(\d{1,4})>{0,2}'
        
        def fix_placeholder(match):
            block_type = match.group(1)
            index = int(match.group(2))
            
            # æŸ¥æ‰¾å¯¹åº”çš„å®Œæ•´å ä½ç¬¦
            expected_placeholder = f"<<<{block_type}_{index:04d}>>>"
            
            # åœ¨all_blocksä¸­æŸ¥æ‰¾
            for block in all_blocks:
                if block.placeholder == expected_placeholder:
                    return block.original
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸæ–‡ï¼ˆä¿ç•™æ®‹ç¼ºå ä½ç¬¦ç”¨äºè°ƒè¯•ï¼‰
            return match.group(0)
        
        return re.sub(broken_pattern, fix_placeholder, text)
    
    def validate_translation_completeness(self, original: str, translated: str) -> Dict[str, any]:
        """éªŒè¯ç¿»è¯‘å®Œæ•´æ€§
        
        Args:
            original: åŸå§‹æ–‡æœ¬
            translated: ç¿»è¯‘åçš„æ–‡æœ¬
        
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        result = {
            "is_valid": True,
            "issues": []
        }
        
        # 1. æ£€æŸ¥å ä½ç¬¦æ•°é‡
        original_placeholders = re.findall(r'<<<[A-Z_]+_\d{4}>>>', original)
        translated_placeholders = re.findall(r'<<<[A-Z_]+_\d{4}>>>', translated)
        
        if len(original_placeholders) != len(translated_placeholders):
            result["is_valid"] = False
            result["issues"].append(f"å ä½ç¬¦æ•°é‡ä¸åŒ¹é…: åŸæ–‡{len(original_placeholders)}ä¸ª, è¯‘æ–‡{len(translated_placeholders)}ä¸ª")
        
        # 2. æ£€æŸ¥æ®µè½æ•°é‡
        original_paragraphs = [p for p in original.split('\n\n') if p.strip()]
        translated_paragraphs = [p for p in translated.split('\n\n') if p.strip()]
        
        if len(original_paragraphs) != len(translated_paragraphs):
            diff = abs(len(original_paragraphs) - len(translated_paragraphs))
            result["issues"].append(f"æ®µè½æ•°é‡å·®å¼‚: åŸæ–‡{len(original_paragraphs)}æ®µ, è¯‘æ–‡{len(translated_paragraphs)}æ®µ (å·®å¼‚{diff}æ®µ)")
            if diff > len(original_paragraphs) * 0.2:  # å·®å¼‚è¶…è¿‡20%
                result["is_valid"] = False
        
        # 3. æ£€æŸ¥è¡Œæ•°
        original_lines = [l for l in original.split('\n') if l.strip()]
        translated_lines = [l for l in translated.split('\n') if l.strip()]
        
        if len(original_lines) != len(translated_lines):
            diff = abs(len(original_lines) - len(translated_lines))
            result["issues"].append(f"è¡Œæ•°å·®å¼‚: åŸæ–‡{len(original_lines)}è¡Œ, è¯‘æ–‡{len(translated_lines)}è¡Œ (å·®å¼‚{diff}è¡Œ)")
            if diff > len(original_lines) * 0.15:  # å·®å¼‚è¶…è¿‡15%
                result["is_valid"] = False
        
        # 4. æ£€æŸ¥å†…å®¹é•¿åº¦æ¯”ä¾‹ï¼ˆä¸­æ–‡é€šå¸¸æ¯”è‹±æ–‡çŸ­ï¼‰
        # å‡è®¾ä¸­è‹±æ–‡æ¯”ä¾‹åœ¨ 0.5 åˆ° 1.2 ä¹‹é—´æ˜¯åˆç†çš„
        length_ratio = len(translated) / len(original) if len(original) > 0 else 0
        if length_ratio < 0.3 or length_ratio > 1.5:
            result["is_valid"] = False
            result["issues"].append(f"å†…å®¹é•¿åº¦å¼‚å¸¸: ä¸­è‹±æ–‡æ¯”ä¾‹ {length_ratio:.2f} (é¢„æœŸ 0.3-1.5)")
        
        return result
    
    def post_optimize_translation(self, text: str) -> str:
        """ç¿»è¯‘åçš„æ•´ä½“ä¼˜åŒ–
        
        Args:
            text: ç¿»è¯‘åçš„æ–‡æœ¬
        
        Returns:
            ä¼˜åŒ–åçš„æ–‡æœ¬
        """
        if not text.strip():
            return text
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘è¿›è¡Œæ•´ä½“ä¼˜åŒ–ï¼Œæå‡è¯­è¨€æµç•…åº¦å’Œè¿è´¯æ€§ã€‚

**ä¼˜åŒ–è¦æ±‚**ï¼š
1. **ç»å¯¹ä¸èƒ½åˆ é™¤ä»»ä½•å†…å®¹**ï¼šè¿™æ˜¯æœ€é‡è¦çš„åŸåˆ™ï¼åªèƒ½ä¼˜åŒ–è¯­è¨€è¡¨è¾¾ï¼Œä¸èƒ½åˆ é™¤ä»»ä½•æ®µè½ã€å¥å­æˆ–è¯è¯­
2. **ä¿æŒç»“æ„å®Œæ•´**ï¼šæ‰€æœ‰æ®µè½ã€æ ‡é¢˜ã€åˆ—è¡¨é¡¹ç­‰ç»“æ„å¿…é¡»ä¿æŒä¸å˜
3. **åªæ¶¦è‰²è¯­è¨€**ï¼šä¼˜åŒ–å¥å¼ã€ç”¨è¯ã€è¿æ¥è¯ç­‰ï¼Œä½¿è¡¨è¾¾æ›´æµç•…è‡ªç„¶
4. **ä¿æŒå­¦æœ¯é£æ ¼**ï¼šä½¿ç”¨æ­£å¼çš„ä¸­æ–‡å­¦æœ¯è¯­è¨€
5. **ä¿æŒæ ¼å¼**ï¼šæ‰€æœ‰Markdownæ ¼å¼æ ‡è®°å¿…é¡»ä¿æŒä¸å˜
6. **ä¿ç•™å ä½ç¬¦**ï¼šä¸è¦ä¿®æ”¹ <<<XXX_NNNN>>> æ ¼å¼çš„å ä½ç¬¦

**é‡è¦æç¤º**ï¼š
- ä½ çš„ä»»åŠ¡åªæ˜¯æ¶¦è‰²è¯­è¨€ï¼Œè®©ç¿»è¯‘è¯»èµ·æ¥æ›´æµç•…
- ä¸å¾—æ”¹å˜åŸæ–‡çš„ç»“æ„å’Œå†…å®¹æ•°é‡
- ä¸å¾—åˆ é™¤ä»»ä½•æ®µè½æˆ–å¥å­
- å¦‚æœæŸä¸ªæ®µè½å·²ç»æœ‰é—®é¢˜ï¼Œåªèƒ½ä¼˜åŒ–å…¶è¡¨è¾¾ï¼Œä¸èƒ½åˆ é™¤

å¾…ä¼˜åŒ–çš„ä¸­æ–‡æ–‡æœ¬ï¼š
```markdown
{text}
```

è¯·ç›´æ¥è¿”å›ä¼˜åŒ–åçš„ä¸­æ–‡Markdownå†…å®¹ã€‚"""
        
        optimized = self.call_api(prompt, max_tokens=15000, temperature=0.2)
        
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
        optimized = re.sub(r'^```markdown\s*', '', optimized)
        optimized = re.sub(r'\s*```\s*$', '', optimized)
        
        return optimized
    
    def translate_text(self, text: str, context: str = "") -> str:
        """ç¿»è¯‘æ–‡æœ¬
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå‰ä¸€æ®µçš„æœ€åå‡ å¥ï¼‰ï¼Œç”¨äºä¿æŒè¿è´¯æ€§
        """
        if not text.strip():
            return text
        
        context_part = f"\n\n**ä¸Šä¸‹æ–‡å‚è€ƒ**ï¼ˆå‰æ®µæœ«å°¾ï¼Œç”¨äºä¿æŒè¿è´¯æ€§ï¼Œåªéœ€ç¿»è¯‘æœ¬æ®µï¼‰ï¼š\n```markdown\n{context}\n```\n" if context.strip() else ""
        
        prompt = f"""è¯·å°†ä»¥ä¸‹Markdownå†…å®¹ç¿»è¯‘æˆä¸­æ–‡ã€‚

**ç¿»è¯‘è¦æ±‚**ï¼š
1. **å¿…é¡»ç¿»è¯‘æ‰€æœ‰è‹±æ–‡æ­£æ–‡å†…å®¹**ï¼šè¿™æ˜¯æœ€é‡è¦çš„è¦æ±‚ï¼æ¯ä¸ªè‹±æ–‡å¥å­ã€æ¯ä¸ªæ®µè½éƒ½å¿…é¡»ç¿»è¯‘æˆä¸­æ–‡
2. **é€å¥é€æ®µå®Œæ•´ç¿»è¯‘**ï¼šä¸å¾—é—æ¼ä»»ä½•å†…å®¹ï¼Œä¸å¾—çœç•¥ä»»ä½•å¥å­
3. **ä¿æŒæ ¼å¼**ï¼šä¿ç•™æ‰€æœ‰Markdownæ ‡è®°ï¼ˆ# ## ### ** * ç­‰ï¼‰
4. **ä¿æŠ¤å†…å®¹ä¸ç¿»è¯‘**ï¼š
   - ä»£ç å—ä¸­çš„ä»£ç ï¼ˆåªæœ‰æ³¨é‡Šéœ€è¦ç¿»è¯‘ï¼‰
   - æ•°å­¦å…¬å¼
   - äººåï¼ˆå¦‚ John Smith, Alice Johnsonï¼‰ä¿æŒè‹±æ–‡
   - ä¸“æœ‰åè¯å’ŒæŠ€æœ¯æœ¯è¯­ï¼ˆå¦‚ Python, TensorFlow, CNNï¼‰å¯ä»¥ä¿ç•™è‹±æ–‡æˆ–ç¿»è¯‘
   - æ–‡ä»¶è·¯å¾„å’ŒURL
5. **è¡¨æ ¼å¤„ç†**ï¼š
   - è¡¨å¤´éœ€è¦ç¿»è¯‘
   - è¡¨æ ¼å†…å®¹å¦‚æœæ˜¯æ•°æ®/ä»£ç ä¸ç¿»è¯‘
   - è¡¨æ ¼å†…å®¹å¦‚æœæ˜¯æ–‡å­—åˆ™ç¿»è¯‘
6. **å­¦æœ¯é£æ ¼**ï¼šä½¿ç”¨æ­£å¼çš„ä¸­æ–‡å­¦æœ¯è¯­è¨€
7. **ä¿ç•™å ä½ç¬¦**ï¼šä¸è¦ä¿®æ”¹ <<<XXX_NNNN>>> æ ¼å¼çš„å ä½ç¬¦

**é‡è¦æç¤º**ï¼š
- ä½ ä¼šçœ‹åˆ°ä¸€äº›å ä½ç¬¦å¦‚ <<<CODE_BLOCK_0000>>>ã€<<<MATH_BLOCK_0001>>>ã€<<<INLINE_MATH_0002>>> ç­‰
- è¿™äº›æ˜¯ä¿æŠ¤çš„å†…å®¹ï¼Œ**ç»å¯¹ä¸è¦ç¿»è¯‘æˆ–ä¿®æ”¹è¿™äº›å ä½ç¬¦**
- ç›´æ¥ä¿ç•™è¿™äº›å ä½ç¬¦åœ¨åŸæ–‡ä½ç½®ï¼Œä¸è¦åˆ é™¤æˆ–æ›´æ”¹
- ç‰¹åˆ«æ˜¯ <<<INLINE_MATH_XXXX>>> ä»£è¡¨è¡Œå†…æ•°å­¦å…¬å¼ï¼Œå¿…é¡»å®Œæ•´ä¿ç•™
- **ä¸¥ç¦è·³è¿‡ä»»ä½•æ®µè½æˆ–å†…å®¹ä¸ç¿»è¯‘**ï¼Œå¿…é¡»é€å­—é€å¥ç¿»è¯‘å…¨éƒ¨å†…å®¹

{context_part}
**å¾…ç¿»è¯‘å†…å®¹**ï¼ˆå¿…é¡»å…¨éƒ¨ç¿»è¯‘ï¼‰ï¼š
```markdown
{text}
```

è¯·ç›´æ¥è¿”å›ç¿»è¯‘åçš„ä¸­æ–‡Markdownå†…å®¹ï¼Œç¡®ä¿ç¿»è¯‘å®Œæ•´ï¼Œæ²¡æœ‰é—æ¼ã€‚"""
        
        translated = self.call_api(prompt, max_tokens=10000, temperature=0.3)
        
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
        translated = re.sub(r'^```markdown\s*', '', translated)
        translated = re.sub(r'\s*```\s*$', '', translated)
        
        return translated
    
    def get_context_from_previous_chunk(self, previous_chunk: str, num_lines: int = 3) -> str:
        """ä»å‰ä¸€æ®µæå–æœ«å°¾å‡ è¡Œä½œä¸ºä¸Šä¸‹æ–‡
        
        Args:
            previous_chunk: å‰ä¸€æ®µçš„åŸå§‹å†…å®¹
            num_lines: æå–çš„è¡Œæ•°
        
        Returns:
            ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not previous_chunk:
            return ""
        
        lines = [line for line in previous_chunk.split('\n') if line.strip()]
        if not lines:
            return ""
        
        # æå–æœ€åå‡ è¡Œ
        context_lines = lines[-num_lines:]
        return '\n'.join(context_lines)
    
    def translate_large_document(self, text: str) -> str:
        """ç¿»è¯‘å¤§å‹æ–‡æ¡£ï¼ˆåˆ†æ®µå¤„ç†ï¼‰"""
        # ä¿æŠ¤æ‰€æœ‰å†…å®¹ï¼ˆä¸€æ¬¡æ€§ä¿æŠ¤æ•´ä¸ªæ–‡æ¡£ï¼‰
        print("  ğŸ”’ æ­£åœ¨ä¿æŠ¤ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹...")
        protected_text, all_protected_blocks = self.protect_blocks(text)
        inline_math_count = len([b for b in all_protected_blocks if b.block_type == "inline_math"])
        math_block_count = len([b for b in all_protected_blocks if b.block_type == "math_block"])
        print(f"     å·²ä¿æŠ¤ {len(all_protected_blocks)} ä¸ªå†…å®¹å—")
        print(f"        - è¡Œå†…å…¬å¼: {inline_math_count}")
        print(f"        - å…¬å¼å—: {math_block_count}")
        print(f"        - ä»£ç å—: {len([b for b in all_protected_blocks if b.block_type == 'code_block'])}")
        print(f"        - å›¾ç‰‡: {len([b for b in all_protected_blocks if b.block_type == 'image'])}")
        
        # å¦‚æœæ–‡æ¡£è¾ƒå°ï¼Œç›´æ¥ç¿»è¯‘
        if len(protected_text) < 8000:
            print("  ğŸŒ æ–‡æ¡£è¾ƒå°ï¼Œç›´æ¥ç¿»è¯‘...")
            translated = self.translate_text(protected_text)
            print("  ğŸ”“ æ­£åœ¨æ¢å¤ä¿æŠ¤çš„å†…å®¹...")
            final_text = self.restore_blocks(translated, all_protected_blocks)
            
            # ä¿®å¤å¯èƒ½çš„æ®‹ç¼ºå ä½ç¬¦
            broken_placeholders = re.findall(r'<<<[A-Z_]+_\d{1,4}>{1,2}(?!>)', final_text)
            if broken_placeholders:
                print(f"  âš ï¸ å‘ç° {len(broken_placeholders)} ä¸ªæ®‹ç¼ºçš„å ä½ç¬¦ï¼Œæ­£åœ¨ä¿®å¤...")
                final_text = self.fix_broken_placeholders(final_text, all_protected_blocks)
            
            return final_text
        
        # å¤§å‹æ–‡æ¡£åˆ†æ®µç¿»è¯‘
        print(f"  ğŸ“„ æ–‡æ¡£è¾ƒå¤§ ({len(text)} å­—ç¬¦)ï¼Œå°†åˆ†æ®µç¿»è¯‘...")
        
        # æŒ‰æ®µè½åˆ†å‰²
        lines = protected_text.split('\n')
        chunks = []
        current_chunk_lines = []
        current_size = 0
        chunk_size_limit = 6000
        
        for line in lines:
            line_size = len(line)
            
            if current_size + line_size > chunk_size_limit and current_chunk_lines:
                if line.startswith('#') or line.strip() == '' or line.startswith('---'):
                    chunks.append('\n'.join(current_chunk_lines))
                    current_chunk_lines = [line]
                    current_size = line_size
                else:
                    chunks.append('\n'.join(current_chunk_lines))
                    current_chunk_lines = [line]
                    current_size = line_size
            else:
                current_chunk_lines.append(line)
                current_size += line_size
        
        if current_chunk_lines:
            chunks.append('\n'.join(current_chunk_lines))
        
        print(f"  ğŸ“¦ å°†åˆ†ä¸º {len(chunks)} æ®µè¿›è¡Œç¿»è¯‘")
        
        # ä¸ºæ¯ä¸ªchunkç¡®å®šåŒ…å«å“ªäº›ä¿æŠ¤å—
        translated_chunks = []
        
        for i, chunk in enumerate(chunks):
            # æ‰¾å‡ºè¯¥chunkåŒ…å«çš„ä¿æŠ¤å—
            chunk_blocks = []
            for block in all_protected_blocks:
                if block.placeholder in chunk:
                    chunk_blocks.append(block)
            
            # è·å–å‰ä¸€æ®µçš„ä¸Šä¸‹æ–‡
            context = ""
            if i > 0:
                context = self.get_context_from_previous_chunk(chunks[i-1], num_lines=3)
            
            print(f"  ğŸ”„ æ­£åœ¨ç¿»è¯‘ç¬¬ {i+1}/{len(chunks)} æ®µ (åŒ…å« {len(chunk_blocks)} ä¸ªä¿æŠ¤å—)...")
            if context:
                print(f"     âœ“ å·²æ·»åŠ å‰æ®µä¸Šä¸‹æ–‡ ({len(context)} å­—ç¬¦)")
            
            # ç¿»è¯‘ï¼Œä¼ å…¥ä¸Šä¸‹æ–‡
            translated_chunk = self.translate_text(chunk, context=context)
            
            # æ¢å¤è¯¥æ®µçš„ä¿æŠ¤å—
            if chunk_blocks:
                translated_chunk = self.restore_blocks(translated_chunk, chunk_blocks)
            
            translated_chunks.append(translated_chunk)
        
        # åˆå¹¶æ‰€æœ‰ç¿»è¯‘ç‰‡æ®µ
        full_translated = '\n'.join(translated_chunks)
        
        # æ£€æŸ¥å¹¶ä¿®å¤æ®‹ç¼ºçš„å ä½ç¬¦
        broken_placeholders = re.findall(r'<<<[A-Z_]+_\d{1,4}>{1,2}(?!>)', full_translated)
        if broken_placeholders:
            print(f"  âš ï¸ å‘ç° {len(broken_placeholders)} ä¸ªæ®‹ç¼ºçš„å ä½ç¬¦ï¼Œæ­£åœ¨ä¿®å¤...")
            full_translated = self.fix_broken_placeholders(full_translated, all_protected_blocks)
        
        # æœ€åæ£€æŸ¥æ˜¯å¦æœ‰æœªæ¢å¤çš„å ä½ç¬¦
        remaining_placeholders = re.findall(r'<<<[A-Z_]+_\d{4}>>>', full_translated)
        if remaining_placeholders:
            print(f"  âš ï¸ å‘ç° {len(remaining_placeholders)} ä¸ªæœªæ¢å¤çš„å ä½ç¬¦ï¼Œå°è¯•é‡æ–°æ¢å¤...")
            full_translated = self.restore_blocks(full_translated, all_protected_blocks)
        
        return full_translated
    
    def process_markdown_file(self, input_path: str) -> str:
        """å¤„ç†Markdownæ–‡ä»¶"""
        print(f"\nğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {input_path}")
        
        # è¯»å–æ–‡ä»¶
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"âœ… å·²è¯»å– ({len(content)} å­—ç¬¦)")
        
        # ç¿»è¯‘
        print("\nğŸŒ å¼€å§‹ç¿»è¯‘...")
        translated_content = self.translate_large_document(content)
        
        # éªŒè¯ç¿»è¯‘å®Œæ•´æ€§
        print("\nğŸ” éªŒè¯ç¿»è¯‘å®Œæ•´æ€§...")
        validation_result = self.validate_translation_completeness(content, translated_content)
        
        if validation_result["issues"]:
            for issue in validation_result["issues"]:
                print(f"  âš ï¸  {issue}")
            if validation_result["is_valid"]:
                print(f"  â„¹ï¸  ç¿»è¯‘åŸºæœ¬å®Œæ•´ï¼Œä½†å­˜åœ¨ä¸€äº›å·®å¼‚")
            else:
                print(f"  âŒ ç¿»è¯‘å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®äººå·¥æ£€æŸ¥")
        else:
            print(f"  âœ… ç¿»è¯‘å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        
        # æ•´ä½“ä¼˜åŒ–ç¿»è¯‘ï¼ˆæå‡è¯­è¨€è¿è´¯æ€§ï¼‰
        print("\nâœ¨ æ­£åœ¨è¿›è¡Œæ•´ä½“ä¼˜åŒ–...")
        print(f"   åŸå­—ç¬¦æ•°: {len(translated_content)}")
        optimized_content = self.post_optimize_translation(translated_content)
        print(f"   ä¼˜åŒ–åå­—ç¬¦æ•°: {len(optimized_content)}")
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        input_path_obj = Path(input_path)
        output_path = input_path_obj.parent / f"{input_path_obj.stem}_zh{input_path_obj.suffix}"
        
        # ä¿å­˜
        print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_path}")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(optimized_content)
        
        # æœ€ç»ˆæ£€æŸ¥
        remaining_placeholders = re.findall(r'<<<[A-Z_]+_\d{4}>>>', optimized_content)
        broken_placeholders = re.findall(r'<<<[A-Z_]+_\d{1,4}>{1,2}(?!>)', optimized_content)
        
        if remaining_placeholders or broken_placeholders:
            if remaining_placeholders:
                print(f"\nâš ï¸ è­¦å‘Š: è¾“å‡ºä¸­ä»æœ‰ {len(remaining_placeholders)} ä¸ªæœªæ¢å¤çš„å®Œæ•´å ä½ç¬¦")
            if broken_placeholders:
                print(f"\nâš ï¸ è­¦å‘Š: è¾“å‡ºä¸­ä»æœ‰ {len(broken_placeholders)} ä¸ªæ®‹ç¼ºçš„å ä½ç¬¦:")
                for ph in broken_placeholders[:5]:
                    print(f"   - {ph}")
                if len(broken_placeholders) > 5:
                    print(f"   ... è¿˜æœ‰ {len(broken_placeholders)-5} ä¸ª")
            print(f"\nğŸ’¡ æç¤º: å¦‚æœçœ‹åˆ°å ä½ç¬¦ï¼Œè¯´æ˜è¯¥éƒ¨åˆ†å†…å®¹æœªè¢«æ­£ç¡®æ¢å¤")
        else:
            print(f"âœ… æ‰€æœ‰ä¿æŠ¤å†…å®¹å·²æ­£ç¡®æ¢å¤")
        
        print(f"\nâœ… ç¿»è¯‘å®Œæˆï¼")
        print(f"   è¾“å…¥: {input_path}")
        print(f"   è¾“å‡º: {output_path}")
        print(f"   æœ€ç»ˆå­—ç¬¦æ•°: {len(optimized_content)}")
        
        return str(output_path)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å°†è‹±æ–‡Markdownæ–‡ä»¶ç¿»è¯‘æˆä¸­æ–‡"
    )
    parser.add_argument("input_file", help="è¾“å…¥çš„è‹±æ–‡Markdownæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--api-key", default=os.getenv("TRANSLATE_API_KEY", ""), help="APIå¯†é’¥")
    parser.add_argument("--api-base", default=os.getenv("TRANSLATE_API_BASE", "https://api.openai.com/v1"), help="APIåŸºç¡€URL")
    parser.add_argument("--model", default=os.getenv("TRANSLATE_MODEL", "gpt-4o"), help="æ¨¡å‹åç§°")
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        sys.exit(1)
    
    if not args.input_file.endswith('.md'):
        print(f"âš ï¸  è­¦å‘Š: è¾“å…¥æ–‡ä»¶ä¸æ˜¯ .md æ–‡ä»¶: {args.input_file}")
    
    # éªŒè¯APIé…ç½®
    if not args.api_key:
        print("âŒ é”™è¯¯: æœªé…ç½®APIå¯†é’¥ï¼ˆAPI_KEYï¼‰")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ API_KEY æˆ–ä½¿ç”¨ --api-key å‚æ•°")
        sys.exit(1)
    
    # åˆ›å»ºç¿»è¯‘å™¨
    translator = MarkdownTranslator(
        api_key=args.api_key,
        api_base=args.api_base,
        model=args.model
    )
    
    # å¤„ç†æ–‡ä»¶
    try:
        output_path = translator.process_markdown_file(args.input_file)
        print(f"\nğŸ‰ æˆåŠŸç”Ÿæˆä¸­æ–‡Markdownæ–‡ä»¶ï¼")
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
